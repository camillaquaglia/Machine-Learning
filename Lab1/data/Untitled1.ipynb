{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sl\n",
    "from scipy import stats\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDnumber = 1242830  #YOUR_ID , try also to change the seed to see the impact of random initialization on the results\n",
    "np.random.seed(IDnumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Position', 'Height cm', 'kg', 'Age']\n",
      "The length of the dataset is 260 rows\n"
     ]
    }
   ],
   "source": [
    "#load the dataset\n",
    "filename = 'NBA.csv'\n",
    "NBA = csv.reader(open(filename, newline=''), delimiter=',')\n",
    "\n",
    "header = next(NBA) #skip first line\n",
    "print(header)\n",
    "\n",
    "dataset = list(NBA)\n",
    "for i in range(len(dataset)):\n",
    "    dataset[i] = [int(x) for x in dataset[i]]\n",
    "    \n",
    "dataset = np.asarray(dataset)\n",
    "\n",
    "X = dataset[:,1:4] #columns 1,2,3 contain the features\n",
    "Y = dataset[:,0]  # column 0: labels\n",
    "\n",
    "Y = Y*2-1  # set labels to -1, 1 as required by perceptron implementation\n",
    "\n",
    "m = dataset.shape[0]\n",
    "print(\"The length of the dataset is\",m,\"rows\")\n",
    "permutation = np.random.permutation(m) # random permurtation\n",
    "\n",
    "X = X[permutation]\n",
    "Y = Y[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set contains at least 10 elements of class 1 AND at least 10 elements of class -1\n",
      ".................................................\n",
      "Now the training set is ok!\n",
      "[-1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1  1  1 -1  1 -1  1  1  1  1 -1 -1\n",
      "  1  1 -1 -1  1 -1 -1  1  1  1 -1 -1  1 -1 -1 -1  1 -1  1 -1  1  1 -1  1\n",
      "  1 -1  1  1 -1 -1  1 -1  1 -1 -1 -1 -1  1 -1  1 -1 -1  1 -1 -1  1 -1 -1\n",
      "  1 -1  1  1  1  1  1  1  1  1 -1 -1  1 -1  1 -1  1 -1 -1  1  1  1  1 -1\n",
      "  1  1 -1 -1  1  1  1  1 -1 -1 -1 -1 -1  1  1  1  1 -1  1  1 -1 -1 -1  1\n",
      " -1 -1 -1 -1 -1  1  1  1  1  1 -1 -1  1 -1  1  1  1 -1 -1  1 -1  1 -1  1\n",
      "  1 -1 -1  1  1  1 -1  1  1  1 -1 -1 -1 -1  1  1 -1 -1 -1  1  1 -1  1 -1\n",
      "  1 -1 -1 -1 -1  1 -1  1  1  1  1 -1 -1  1]\n",
      "78\n",
      "Shape of training set: (182, 3)\n",
      "Shape of test set: (78, 3)\n"
     ]
    }
   ],
   "source": [
    "#Divide in training and test: make sure that your training set\n",
    "#contains at least 10 elements from class 1 and at least 10 elements\n",
    "#from class -1! If it does not, modify the code so to apply more random\n",
    "#permutations (or the same permutation multiple times) until this happens.\n",
    "#IMPORTANT: do not change the random seed.\n",
    "\n",
    "#m_training needs to be the number of samples in the training set\n",
    "m_training = int((len(X)*70)/100) # m_training must be an integer number\n",
    "                                  # equal to the 70% of the data\n",
    "\n",
    "#m_test needs to be the number of samples in the test set\n",
    "m_test = int((len(X)*30)/100)  # m_test must be an integer number\n",
    "                               # equal to the 30% of the data\n",
    "\n",
    "#X_training = instances for training set\n",
    "X_training = X[:m_training]\n",
    "#Y_training = labels for the training set\n",
    "Y_training = Y[:m_training]\n",
    "\n",
    "if (np.count_nonzero(Y_training == 1) >= 10) & (np.count_nonzero(Y_training == -1) >= 10):\n",
    "    print(\"The training set contains at least 10 elements of class 1 AND at least 10 elements of class -1\")\n",
    "else: \n",
    "    print(\"The training set needs permutations\")\n",
    "    while((np.count_nonzero(Y_training == 1) < 10 )|(np.count_nonzero(Y_training == -1) < 10 )):\n",
    "        permutation = np.random.permutation(m)\n",
    "        m = dataset.shape[0]\n",
    "        permutation = np.random.permutation(m) # random permutation\n",
    "        X = X[permutation]\n",
    "        Y = Y[permutation]\n",
    "        X_training = X[:m_training]\n",
    "        Y_training = Y[:m_training]\n",
    "        \n",
    "print(\".................................................\")\n",
    "if (np.count_nonzero(Y_training == -1) >= 10 ) & (np.count_nonzero(Y_training == 1) >= 10 ) :\n",
    "    print(\"Now the training set is ok!\")\n",
    "#X_test = instances for test set\n",
    "X_test = X[m_training::]\n",
    "#Y_test = labels for the test set\n",
    "Y_test = Y[m_training::]\n",
    "\n",
    "print(Y_training) #to make sure that Y_training contains both 1 and -1\n",
    "print(m_test)\n",
    "\n",
    "print(\"Shape of training set: \" + str(X_training.shape))\n",
    "print(\"Shape of test set: \" + str(X_test.shape)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a 1 to each sample (homogeneous coordinates)\n",
    "X_training = np.hstack((np.ones((m_training,1)),X_training)) \n",
    "X_test = np.hstack((np.ones((m_test,1)),X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(X, Y, max_num_iterations):\n",
    "    \n",
    "    #initialize\n",
    "    best_w = np.zeros((np.size(X,1)))\n",
    "    temp_w = np.zeros((np.size(X,1)))\n",
    "    array_errs = []\n",
    "    error = 0\n",
    "    iterations = 0\n",
    "    \n",
    "    #check for misclassified with initialization values, can be avoided\n",
    "    #since all weights are 0's and whole training set will be considered as misclassified\n",
    "    for k in range(m_training):\n",
    "        if ( (Y[k]*np.dot(X[k],best_w) ) <= 0 ):\n",
    "            array_errs.append(k)\n",
    "    best_error = len(array_errs)/m_training\n",
    "    \n",
    "    #for now best_w is all zeros\n",
    "    #and best_errs are misclassified examples using it  \n",
    "    #real perceptron\n",
    "    for iterations in range(max_num_iterations):\n",
    "        index = np.random.choice(array_errs) #draw from misclassified ones\n",
    "        temp_w += Y[index]*X[index]          #then update the temp_w (1 iteration)\n",
    "        array_errs = []\n",
    "        \n",
    "        for k in range(m_training): #check for errors in whole training dataset with sol\n",
    "            if ( (Y[k]*np.dot(X[k],temp_w)) <= 0 ): #this is a missclassification\n",
    "                array_errs.append(k)\n",
    "        error = len(array_errs)/m_training\n",
    "        \n",
    "        if (error == 0): \n",
    "            print(\"Optimal solution found!\")\n",
    "            best_w = temp_w \n",
    "            best_error = error\n",
    "            break\n",
    "            \n",
    "        if (error < best_error):\n",
    "            best_w = temp_w #if it is smaller then update best_w and best_err\n",
    "            best_error = error\n",
    "    \n",
    "    return best_w, best_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A template is provided, but feel free to build a different implementation\n",
    "\n",
    "def perceptron(X, Y, max_num_iterations):\n",
    "    # Place in this function the main section of the perceptron algorithm\n",
    "    \n",
    "    #init the algorith with w=0, use a best_w variable to keep track of the best solution\n",
    "    curr_w = np.zeros((np.size(X,1))) # initialize to zeros\n",
    "    best_w = np.zeros((np.size(X,1))) # initialize to zeros\n",
    " \n",
    "    best_error = 0\n",
    "    error = 0\n",
    "    num_iter = 0\n",
    "    misclassified = []\n",
    "    \n",
    "\n",
    "    num_misclassified = len(misclassified)\n",
    "    index_misclassified = range(num_misclassified+1)\n",
    "    \n",
    "    for i in range(m_training):\n",
    "        if ( (Y[i]*np.dot(X[i],best_w) ) <= 0 ):\n",
    "             misclassified.append(i)\n",
    "    best_error = num_misclassified/m_training\n",
    "    \n",
    "    while ((index_misclassified != -1) and (num_iter < max_num_iterations)):\n",
    "        \n",
    "        index_misclassified = -1\n",
    "        num_misclassified = 0\n",
    "        index_misclassified  = np.random.choice(misclassified)\n",
    "        # avoid working always on the same sample, \n",
    "        # you can use a random permutation or randomize the choice of misclassified\n",
    "        \n",
    "        curr_w += Y[index_misclassified]*X[index_misclassified] \n",
    "        misclassified = []\n",
    "        \n",
    "        for i in range(m_training):\n",
    "            if ((Y[i]*np.dot(X[i],curr_w)) <= 0 ): \n",
    "                misclassified.append(i)\n",
    "        error = len(misclassified)/m_training\n",
    "        \n",
    "        if (error == 0): \n",
    "            print(\"The optimal solution is found\")\n",
    "            best_w = curr_w \n",
    "            best_error = error\n",
    "            break  # go out of the cicle\n",
    "            \n",
    "        if (error < best_error):\n",
    "            best_w = curr_w \n",
    "            best_error = error\n",
    "            \n",
    "    return best_w, best_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution:  [  1. 213. 114.  25.]\n",
      "Training Error of perpceptron (100 iterations): 0.4945054945054945\n"
     ]
    }
   ],
   "source": [
    "#now run the perceptron for 100 iterations\n",
    "w_found, error = perceptron(X_training,Y_training, 1)\n",
    "print(\"Best solution: \" , w_found)\n",
    "print(\"Training Error of perpceptron (100 iterations): \" + str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
